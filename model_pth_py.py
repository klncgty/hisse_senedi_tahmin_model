# -*- coding: utf-8 -*-
"""model_pth.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R-bZ0rAf1WIKi_NbyLxos3H-YjUCBb9t
"""

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn

symbol = "ANHYT.IS"
end_date = datetime.now()
start_date = end_date - timedelta(days=4*365)  # Son 4 yÄ±l

data = yf.download(symbol, start=start_date, end=end_date)

data = data[['Open', 'Close']]

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

train_data = scaled_data

def create_dataset(dataset, time_step=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), :]
        dataX.append(a)
        dataY.append(dataset[i + time_step, :])
    return np.array(dataX), np.array(dataY)

time_step = 10
X_train, y_train = create_dataset(train_data, time_step)

X_train = torch.Tensor(X_train)
y_train = torch.Tensor(y_train)

class AdvancedLSTM(nn.Module):
    def __init__(self, input_size=2, hidden_layer_size=100, output_size=2, num_layers=2, dropout_prob=0.2):
        super(AdvancedLSTM, self).__init__()
        self.hidden_layer_size = hidden_layer_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, dropout=dropout_prob, batch_first=True)
        self.linear = nn.Linear(hidden_layer_size, output_size)
        self.hidden_cell = (torch.zeros(self.num_layers, 1, self.hidden_layer_size),
                            torch.zeros(self.num_layers, 1, self.hidden_layer_size))

    def forward(self, input_seq):
        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)
        predictions = self.linear(lstm_out.view(len(input_seq), -1))
        return predictions[-1]

model = AdvancedLSTM()
loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

epochs = 1000

for i in range(epochs):
    for seq, labels in zip(X_train, y_train):
        optimizer.zero_grad()
        model.hidden_cell = (torch.zeros(model.num_layers, 1, model.hidden_layer_size),
                        torch.zeros(model.num_layers, 1, model.hidden_layer_size))

        y_pred = model(seq)

        single_loss = loss_function(y_pred, labels)
        single_loss.backward()
        optimizer.step()

    if i%25 == 0:
        print(f'Epoch {i} loss: {single_loss.item()}')

print(f'Epoch {epochs} loss: {single_loss.item()}')

torch.save(model.state_dict(), 'model.pth')